require('torch')
require('nn')
require('nngraph')
require('rnn')
require('optim')
require('mime')
require('image')
local _ = require('underscore')
cjson = require('cjson')
local JSON = require('./JSON')
require('./EBDebug')
require('./EBWrapDebug')
require('./EBWrapTable')
require('{{=it.rootModuleName}}')
require('{{=it.rootCriterionName}}')

-- Define our object, TrainingScript.
-- Do not change the name of this class!
local TrainingScript = {}
TrainingScript.__index = TrainingScript


-- Creates the TrainingScript object.
-- Do not change the name of this class
function TrainingScript.new()
    local self = {}

    setmetatable(self, TrainingScript)

    -- Connect to the other nodes in the process
    self.ipctree = require 'ipc.LocalhostTree'(tonumber(arg[1]), tonumber(arg[2]))
    self.allReduceSGD = require 'distlearn.AllReduceSGD'(self.ipctree)

    -- Try and setup the GPU
    local ok, cunn = pcall(require, 'cunn')
    local ok2, cutorch = pcall(require, 'cutorch')
    if ok and ok2 then
        self.gpuEnabled = true
        cutorch.setDevice(1)
    else
        self.gpuEnabled = false
    end

    -- generate SVG of the graph with the problem node highlighted
    -- and hover over the nodes in svg to see the filename:line_number info
    -- nodes will be annotated with local variable names even if debug mode is not enabled.
    nngraph.setDebug(true)

    -- Increase the stack limit
    --print(coroutine)
    --local olddefault = coroutine.cstacksize({{=(1024 * 1024 * 256)}})

    -- This is a table where we will store loaded data entries
    self.dataEntries = {}

    -- Initialization optimization state
    self.optimState = {}

    -- Is the module initialized
    self.moduleInitialized = false

    return self
end

function TrainingScript:createModule()
    -- Create the main neural network module
    self.module = nn.{{=it.rootModuleName}}(self)
    if self.gpuEnabled then
        self.module:cuda()
    end

    -- Create a copy of the main neural network module that will be used for saving
    self.moduleSaveCopy = nn.{{=it.rootModuleName}}(self)

    -- Create the main criterion for training
    self.criterion = nn.{{=it.rootCriterionName}}(self)
    if self.gpuEnabled then
        self.criterion:cuda()
    end
    self.criterionClones = {}

    -- Prepare the parameters
    self.params, self.gradParams = self.module:getParameters()

    -- Set the module as initialized
    self.moduleInitialized = true
end

function TrainingScript:localize(obj)
    if self.gpuEnabled then
        return obj:cuda()
    else
        return obj
    end
end


function TrainingScript:getCriterion(index)
   local criterion = self.criterionClones[index]
   if not criterion then
      criterion = self.criterion:clone()
      self.criterionClones[index] = criterion
   end
   return criterion
end

function TrainingScript:evaluateTrainingIteration(batch)
    local batchOutputs
    local outputs

    {{= it.generateLocalizeFunction(it.inputSchema, "localizeInputRoot").replace(/\n/g, "\n    ") }}
    {{= it.generateLocalizeFunction(it.outputSchema, "localizeOutputRoot").replace(/\n/g, "\n    ") }}

    if self.gpuEnabled then
        batch.input = localizeInputRoot(batch.input)
        for n=1,#batch.output do
            batch.output[n] = localizeOutputRoot(batch.output[n])
        end
    end

    local iteration = function(params)
        --if params_ ~= self.params then
        --    self.params:copy(params_)
        --end
        self.gradParams:zero()

        local expectedOutputs = {}
        local loss = 0

        ------------------- forward pass -------------------
        self.module:training()

        batchOutputs = self.module:forward(batch.input)
        outputs = self:unwindBatchOutput(batchOutputs)

        ------------------- criterion ----------------------
        -- Separately run each item in the batch through criterion
        local derivatives = {}
        for n=1,#outputs do
            local criterion = self:getCriterion(n)
            loss = loss + criterion:forward(outputs[n], batch.output[n])
            local criterionDerivatives = criterion:backward(outputs[n], batch.output[n])
            table.insert(derivatives, criterionDerivatives)
        end

        ------------------- backward pass -------------------
        local derivativesBatch = localizeOutputRoot(self:prepareDerivatives(derivatives))
        local inputDerivatives = self.module:backward(batch.input, derivativesBatch)

        -- clip gradient element-wise
        self.gradParams:clamp(-5, 5)

        -- Gather the grads from all nodes
        self.allReduceSGD.sumAndNormalizeGradients({self.gradParams})

        return loss, self.gradParams
    end

    local _ignore, loss
    _ignore, loss = optim.{{=it.optimizationAlgorithm}}(iteration, self.params, self.optimState)

    -- Collect gabarge at the end of each iteration - prevents build up of useless memory
    collectgarbage()

    return {
        loss = loss[1],
        output = outputs
    }
end


function TrainingScript:evaluateBatch(batch)
    ------------------- forward pass -------------------
    self.module:evaluate()

    {{= it.generateLocalizeFunction(it.inputSchema, "localizeInputRoot") }}

    if self.gpuEnabled then
        batch.input = localizeInputRoot(batch.input)
    end

    local batchOutputs = self.module:forward(batch.input)
    return self:unwindBatchOutput(batchOutputs)
end

-- Prepares a batch composed of the given data points
function TrainingScript:prepareBatch(samples)
    local batch = {}

    local inputSamples = {}
    for k,v in pairs(samples) do
        table.insert(inputSamples, self.dataEntries[v].input)
    end

    {{= it.prepareBatch(it.inputSchema, "prepareInputRoot").replace(/\n/g, "\n    ") }}

    batch.input = prepareInputRoot(inputSamples)

    local outputSamples = {}
    for k,v in pairs(samples) do
        table.insert(outputSamples, self.dataEntries[v].output)
    end

    batch.output = outputSamples

    return batch
end


-- Prepares a batch of derivatives back from the criterion
function TrainingScript:prepareDerivatives(derivatives)
    {{= it.prepareBatch(it.outputSchema, "prepareDerivativesRoot").replace(/\n/g, "\n    ") }}
    return prepareDerivativesRoot(derivatives)
end


-- Unwinds a given batch output, separating its outputs composed of the given data points
function TrainingScript:unwindBatchOutput(batch1)
    {{= it.unwindBatchOutput(it.outputSchema, "unwindOutputRoot").replace(/\n/g, "\n    ") }}
    return unwindOutputRoot(batch1)
end


-- This method converts a piece of input data from object format into Torch Tensor format.
function TrainingScript:convertInputIn(data1)
    {{= it.convertDataIn(it.inputSchema, "convert").replace(/\n/g, "\n    ") }}
    return convert(data1)
end


-- This method converts a piece of output data from object format into Torch Tensor format.
function TrainingScript:convertOutputIn(data1)
    {{= it.convertDataIn(it.outputSchema, "convert").replace(/\n/g, "\n    ") }}
    return convert(data1)
end


-- This method converts a piece of output data from Torch Tensor format back into regular object format
function TrainingScript:convertOutputOut(data1)
    {{= it.convertDataOut(it.outputSchema, "convert").replace(/\n/g, "\n    ") }}
    return convert(data1)
end


-- This method can be used to send a log message upwards to Electric Brain, which
-- will be visible on the ElectricBrain interface. Useful for debugging.
function TrainingScript:log(message)
    local stackInfo = debug.getinfo(2, 'fSl')
    if stackInfo.func == print then
        stackInfo = debug.getinfo(3, 'fSl')
    end

    local response = {
        type = "log"
    }

    if torch.type(message) == 'string' then
        response.message = message
    else
        response.message = JSON:encode(message, {}, {
           pretty = true,
           indent = "   ",
           align_keys = false,
        })

        if not response.message then
            response.message = tostring(message)
        end
    end

    response.message = stackInfo.source .. ":" .. stackInfo.currentline .. "  " .. response.message

    self:sendResponse(response)
end


-- This method sends a message to the ElectricBrain manager process.
function TrainingScript:sendResponse(response)
    io.write(cjson.encode(response) .. "\n")
    io.flush()
end

-- This is the main loop which communicates with the manager process in Electric Brain code.
-- Its generally best not to change this too much.
function TrainingScript:enterTrainingLoop()
    -- Now start waiting for messages from standard input
    repeat
        local commandString = io.read("*line")
        local command = cjson.decode(commandString)
        if command then
            if command.type == "handshake" then
                -- Send back a handshake response
                self:sendResponse({type = "handshake"})
            elseif command.type == "reset" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- Resets the model with randomly generated parameters
                self.params:uniform(-0.08, 0.08)
                self.gradParams:zero()
                self:sendResponse({type = "resetCompleted"})
            elseif command.type == "iteration" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The iteration command advances the network with one forward and backward pass.
                -- It must be given the filename of a batch that has been prepared in advance
                -- using the "prepareBatch"
                local batchFile = torch.load(command.batchFilename)
                local batch = batchFile.data
                local results = self:evaluateTrainingIteration(batch)

                local convertedResults = {}
                for n = 1,#results.output do
                    local id = batchFile.ids[n]
                    local result = results.output[n]
                    local converted = self:convertOutputOut(result)
                    converted.id = id
                    table.insert(convertedResults, converted)
                end

                local response = {
                    objects = convertedResults,
                    type = "iterationCompleted",
                    loss = results.loss
                }
                self:sendResponse(response)
            elseif command.type == "prepareBatch" then
                -- The prepare batch command assembles a batch and then writes it
                -- out to a file, so that its ready to go for the main training
                -- script
                local batch = self:prepareBatch(command.ids)

                local batchFile = {
                    data = batch,
                    ids = command.ids
                }

                torch.save(command.fileName, batchFile)

                self:sendResponse({type="batchPrepared"})
            elseif command.type == "store" then
                -- The store command is used by the manager process to store a specific data entry for
                -- quick retrieval later. Then data is provided directly inside the JSON object of
                -- the command. It is then prepared by conversion to Torch tensors as needed.

                self.dataEntries[command.id] = {
                    input = self:convertInputIn(command.input),
                    output = self:convertOutputIn(command.output)
                }

                self:sendResponse({type="stored"})
            elseif command.type == "stats" then
                -- The 'stats' command is used to provide statistics up to the surrounding manager
                -- code

                -- Start with garbage collection, so we don't count anything we don't want

                collectgarbage('collect')
                local stats = {
                    memoryUsage = collectgarbage('count')
                }

                self:sendResponse({type="stats", stats = stats})
            elseif command.type == 'forget' then
                -- The forget command is used by the manager process to indicate to forget a particular
                -- data entry. We do this to manage the amount of memory used by the process.

                self.dataEntries[command.id] = nil
                self:sendResponse({type="forgotten"})
            elseif command.type == "evaluate" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The evaluate command runs an object through the network and
                -- return the result
                local batch = self:prepareBatch(command.samples)
                local results = self:evaluateBatch(batch)

                local convertedResults = {}
                for n = 1,#results do
                    local id = command.samples[n]
                    local result = results[n]
                    local converted = self:convertOutputOut(result)
                    converted.id = id
                    table.insert(convertedResults, converted)
                end

                local response = {
                    type = "evaluationCompleted",
                    objects = convertedResults
                }
                self:sendResponse(response)

            elseif command.type == "evaluateBatch" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The evaluate command runs an object through the network and
                -- return the result
                local batchFile = torch.load(command.batchFilename)
                local batch = batchFile.data
                local results = self:evaluateBatch(batch)

                local convertedResults = {}
                for n = 1,#results do
                    local id = batchFile.ids[n]
                    local result = results[n]
                    local converted = self:convertOutputOut(result)
                    converted.id = id
                    table.insert(convertedResults, converted)
                end

                local response = {
                    type = "evaluationCompleted",
                    objects = convertedResults
                }
                self:sendResponse(response)
            elseif command.type == "save" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The save command causes the process to save the trained model out to disk
                self.moduleSaveCopy:getParameters():copy(self.params)
                torch.save("model.t7", self.moduleSaveCopy)
                local response = {type = "saved"}
                self:sendResponse(response)
            elseif command.type == "load" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The load command causes the process to load the trained model from the disk
                self.module = torch.load("model.t7")
                self.moduleSaveCopy = torch.load("model.t7")
                self.params, self.gradParams = self.module:getParameters()
                local response = {type = "loaded"}
                self:sendResponse(response)
            elseif command.type == "synchronize" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The synchronize command forces the process to synchronize its parameters with other processes
                self.allReduceSGD.synchronizeParameters({self.params})
                local response = {type = "synchronized"}
                self:sendResponse(response)
            end

        end
    until false == true -- Repeat forever. For some reason, the simple while True: doesn't actually work in Lua.
end

local script = TrainingScript.new()

-- Override the print function
print = function(message)
    script:log(message)
end

script:enterTrainingLoop()
