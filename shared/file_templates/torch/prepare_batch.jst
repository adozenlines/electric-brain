{{ var topLevelFields = it.schema.topLevelFields; }}
{{ var hasFixedTensor = it.schema.tensorSize > 0 ? 1 : 0; }}
{{ var topLevelSequences = it.schema.topLevelSequences; }}

    local batch{{=it.depth}} = {}
{{?hasFixedTensor}}
    batch{{=it.depth}}[1] = torch.zeros(1, #samples, {{=it.schema.tensorSize}})
    for k,v in pairs(samples{{=it.depth}}) do
        if #samples{{=it.depth}}[k] >= 1 then
            batch{{=it.depth}}[1]:narrow(2, k, 1):copy(samples{{=it.depth}}[k][1])
        end
    end
{{?}}


{{~ topLevelSequences:sequence:index}}
    batch{{=it.depth}}[{{=index+1+hasFixedTensor}}] = {}
    -- First determine what the longest sequence is
    local longest = 0
    for k,v in pairs(samples{{=it.depth}}) do
        if #samples{{=it.depth}}[k] >= 1 then
            longest = math.max(longest, #samples{{=it.depth}}[k][{{=index+1+hasFixedTensor}}])
        end
    end

    -- Prepare the items for each entry
    for n = 1, longest do
        local samples{{=it.depth + 1}} = {}
        for k,v in pairs(samples{{=it.depth}}) do
            if #samples{{=it.depth}}[k] >= 1 and #samples{{=it.depth}}[k][{{=index+1+hasFixedTensor}}] >= n then
                -- Insert an actual sample
                table.insert(samples{{=it.depth + 1}}, samples{{=it.depth}}[k][{{=index+1+hasFixedTensor}}][n])
            else
                -- Insert a blank object
                table.insert(samples{{=it.depth + 1}}, {})
            end
        end

        {{= it.prepareBatch({schema: sequence.items, prepareBatch: it.prepareBatch, depth: it.depth + 1}) }}

        table.insert(batch{{=it.depth}}[{{=index+1+hasFixedTensor}}], batch{{=it.depth + 1}})
    end
{{~}}


{{~ topLevelFields:field:index}}
    {{? field.isBinary }}
    local height, width = samples{{=it.depth}}[1][{{=index+1+hasFixedTensor+topLevelSequences.length}}]:size(2), samples{{=it.depth}}[1][{{=index+1+hasFixedTensor+topLevelSequences.length}}]:size(3)
    batch{{=it.depth}}[{{=index+1+hasFixedTensor+topLevelSequences.length}}] = torch.zeros(#samples,3,height ,width )

        for k,v in pairs(samples{{=it.depth}}) do
            print(batch{{=it.depth}}[1]:narrow(1, k ,1))
            print(samples{{=it.depth}}[k][{{=index+1+hasFixedTensor+topLevelSequences.length}}]:view(1, 3, height, width))
            batch{{=it.depth}}[1]:narrow(1, k , 1):copy(samples{{=it.depth}}[k][{{=index+1+hasFixedTensor+topLevelSequences.length}}]:view(1, 3, height, width))

        end
    {{?}}
{{~}}